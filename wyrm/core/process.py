"""
:module: wyrm.core.process
:auth: Nathan T. Stevens
:email: ntsteven (at) uw.edu
:org: Pacific Northwest Seismic Network
:license: AGPL-3.0

:purpose:
    This module hosts class definitions for Wyrm submodules that process data:

        WindowWyrm - a submodule for sampling a waveform buffer and generating forward-marching
                    windowed copies of these data as they become available
                        PULSE
                            input: DictStream holding MLTraceBuffer objects
                            output: deque holding ComponentStream objects
        MethodWyrm - a submodule for applying a single class method to objects presented to the
                    MethodWyrm
                        PULSE
                            input: deque of objects
                            output: deque of objects
        PredictWyrm - a submodule for runing predictions with a particular PyTorch/SeisBench model
                    architecture with pretrained weight(s) on preprocessed waveform data
                        PULSE:
                            input: deque of preprocessed ComponentStream objects
                            output: deque of MLTrace objects
"""
import torch
import seisbench.models as sbm
import numpy as np
from collections import deque
from obspy import UTCDateTime
from wyrm.data.mltrace import MLTrace, MLTraceBuffer
from wyrm.core._base import Wyrm
from wyrm.data.dictstream import DictStream, ComponentStream
from wyrm.util.compatability import bounded_floatlike, bounded_intlike


class WindowWyrm(Wyrm):
    """
    The WindowWyrm class takes windowing information from an input
    seisbench.models.WaveformModel object and user-defined component
    mapping and data completeness metrics and provides a pulse method
    that iterates across entries in an input DictStream object and
    generates ComponentStream copies of sampled data that pass data completeness
    requirements. These ComponentStreams are then appended to the WindowWyrm's
    queue attribute [a collections.deque object] via an 'append' action
    """

    def __init__(
        self,
        component_aliases={"Z": "Z3", "N": "N1", "E": "E2"},
        reference_component='Z',
        reference_completeness_threshold=0.95,
        model_name="EQTransformer",
        reference_sampling_rate=100.0,
        reference_npts=6000,
        reference_overlap=1800,
        max_pulse_size=1,
        debug=False,
        **options
    ):
        """
        Initialize a WindowWyrm object that samples a DictStream of MLTraceBuffer
        objects and generates ComponentStream copies of windowed data if a reference
        component for a given instrument in the DictStream is present and has
        sufficient data to meet windowing requirements

        :: INPUTS ::
        :param ref_comp: [str] reference component code passed to initialization
                    of ComponentStream objects
        :param component_aliases: [dict] dictionary defining aliases for component
                    codes with keys representing the aliases and values representing
                    iterable strings of component names that correspond to each alias
        :param ref_comp_thresh: [float] fractional completeness threshold value for
                    the reference component when generating a given ComponentStream
        :param model_name: [str] model name to append to the MLTrace.stats in 
                    ComponentStreams generated by this WindowWyrm
        :param reference_sampling_rate: [float] sampling rate in samples per second
                    to which component streams are referenced. In conjunction with
                    the reference_npts, these parameters define window lengths in
                    seconds that are used to sample buffered data. This value is 
                    assigned to ComponentStream's stats.reference_sampling_rate 
                    attribute
        :param reference_npts: [int] number of samples that completely processed
          ComponentStreams' traces
                    must have. This value is assigned to ComponentStreams' 
                    stats.reference_npts attribute
        :param reference_overlap: [int] number of overlapping samples for
                    sequential windows. In conjunction with reference_sampling_rate
                    this dictates the number of seconds the window starttimes
                    are advanced for window generation
        :param max_pulse_size: [int] maximum number of sweeps across every entry
                    in an input DictStream to conduct to try to generate window
                    I.e., maximum number of windows to generate per instrument
                    represented in an input DictStream.
        :param debug: [bool] - run in debug mode?
        :param **options: [kwargs] key-word argument collector to pass to
                    MLTrace.trim() via MLTraceBuffer.trim_copy() methods


        """
        # Initialize/inherit from Wyrm
        super().__init__(max_pulse_size=max_pulse_size, debug=debug)
        # Compatability checks for component_aliases
        if not isinstance(component_aliases, dict):
            raise TypeError('component_aliases must be type dict')
        elif not all(isinstance(_v, str) and _k in _v for _k, _v in component_aliases.items()):
            raise SyntaxError('component_aliases values must be type str and include the key value')
        else:
            self.aliases = component_aliases

        # Compatability check for reference_component
        if not isinstance(reference_component, str):
            raise TypeError('reference_component must be type str')
        elif reference_component not in self.aliases.keys():
            raise KeyError('reference_component is not in component_aliases.keys()')
        refc = reference_component
        
        # Compatability check for reference_completeness_threshold
        reft = bounded_floatlike(
            reference_completeness_threshold,
            name = "reference_completeness_threshold",
            minimum=0,
            maximum=1,
            inclusive=True
        )
        if not isinstance(model_name, str):
            raise TypeError('model_name must be type str')
        else:
            self.model_name = model_name

        # Target sampling rate compat check
        refsr = bounded_floatlike(
            reference_sampling_rate,
            name='reference_sampling_rate',
            minimum=0,
            maximum=None,
            inclusive=False
        )
        # Target window number of samples compat check
        refn = bounded_intlike(
            reference_npts,
            name='reference_npts',
            minimum=0,
            maximum=None,
            inclusive=False
        )
        # Target window number of sample overlap compat check
        refo = bounded_intlike(
            reference_overlap,
            name='reference_overlap',
            minimum=0,
            maximum=None,
            inclusive=False
        )
        self.ref = {'sampling_rate': refsr, 'overlap': refo, 'npts': refn, 'component': refc, 'threshold': reft}
         # Set Defaults and Derived Attributes
        # Calculate window length, window advance, and blinding size in seconds
        self.window_sec = self.ref['npts']/self.ref['sampling_rate']
        self.advance_sec = (self.ref['npts'] - self.ref['overlap'])/self.ref['sampling_rate']

        self.options = options

        # Create dict for holding instrument window starttime values
        self.window_tracker = {}
        # Have futuredate as a standin for minimum starttime during assimilation
        # self.default_starttime = UTCDateTime('2366-12-31T23:59:59.999999')
        # Create queue for output collection of windows
        self.queue = deque()


    def pulse(self, x):
        if not isinstance(x, DictStream):
            raise TypeError
        for _ in range(self.max_pulse_size):
            self.update_window_tracker(x)
            nnew = self.sample_windows(x)
            if nnew == 0:
                break
        y = self.queue
        return y

    def update_window_tracker(self, dst):
        """
        Iterate across a site-level view of an input dictstream `dst` and add new entries
        to the window_tracker index if a new site or instrument is found with data on
        a reference component.
            For Example:
                UW.GNW.--.HH* newly appeared in the `dst` during a earlier part of this pulse.
                this method splits `dst` into a dictionary of DictStream views including
                {'UW.GNW': DictStream(<data here>)}. 
                Since 'UW.GNW' is not in self.window_stream.keys(), the method decends into
                the DictStream object, seeks out a reference component, and uses its starttime
                to initialize windowing for the site, writing an initial reference time at
                the 'site' level of window_tracker, and creating an instrument level sub-entry
                that keeps track of successive window starttimes for that particular instrument (t0i)

                    window_tracker = {'UW.GNW': {'init_t0': <t0>, '--.HH': <t0i>}}
                
                In a subsequent pulse, data from UW.GNW.--.EN* start to buffer in `dst`. Instead
                of using the starttime of those data for forming windows, potentially setting
                windowed data for site UW.GNW out of alignment, a sub-entry for '--.EN' is created
                and uses the 'init_t0' value as a seed point for generating windows. The starttime
                for '--.EN' is then incremented by a sufficient number of window advances such that
                the first window starttime for '--.EN' is the next integer window advance (<dt>) following
                the starttime of data in '--.EN', which may not match the next starttime to be used for '--.HH'

                    window_tracker = {'UW.GNW': {'init_t0': <t0>,
                                                 '--.HH': <t0> + n*<dt>,
                                                 '--.EN': <t0> + m*<dt>}}
        """
        # Split by site
        dict_x_site = dst.split_on_key(key='site')
        # Iterate across site holdings
        for site, dst_site in dict_x_site.keys():
            # FIRST: if site is not in window_tracker, get max_starttime from a ref_comp DictStream
            if site not in self.window_tracker.keys():
                # Generate a sub-view on reference trace(s)
                dict_site_x_comp = dst_site.split_on_key(key='component')
                # Assign a holder for dst_ref
                dst_ref = False
                # Seek dst_ref including aliases
                for _c in self.aliases[self.ref['component']]:
                    if _c in dict_site_x_comp.keys():
                        dst_ref = dict_site_x_comp[_c]
                # If there is a reference component
                if dst_ref:
                    # Use the maximum starttime (latest start) for reference trace(s) as the site reference starttime
                    init_t0 = dst_ref.stats.max_starttime
                    self.window_tracker.update({site: {'init t0': init_t0}})
            # otherwise, fetch the initial starttime assigned to this site
            else:
                init_t0 = self.window_tracker[site]['init t0']
            
            # NEXT: Iterate across instruments at site
            dst_site_dict_x_inst = dst_site.split_on_key(key='inst')
            for inst, dst_inst in dst_site_dict_x_inst.items():
                # If there is a new instrument
                if inst not in self.window_tracker[site]:
                    # GET STARTTIME OF INSTRUMENT, INCREMENTING ADVANCES IF NEEDED
                    # Calculate number of advances difference between initial_t0 and max_starttime of this view
                    dt_adv = dst_inst.stats.max_starttime - init_t0
                    nadv = dt_adv // self.advance_sec
                    # Add one additional advance to start within the data feed to avoid a front gap
                    if dt_adv > 0:
                        first_t0 = init_t0 + (nadv + 1)*self.advance_sec
                    else:
                        first_t0 = init_t0
                    # GET REFERENCE COMPONENT NATIVE COMPONENT CODE
                    # Get native component code for alias
                    _irc = False
                    native_components = [_tr.component for _tr in dst_inst]
                    if self.ref['component'] not in native_components:
                        for _c in self.aliases[self.ref['component']]:
                            if _c in native_components:
                                _irc = _c
                    else:
                        _irc = self.ref['component']
                    # If the reference component is present, update window_tracker with new site information
                    if _irc:
                        self.window_tracker[site].update({inst: {'t0i':first_t0, 'nrc': _irc}})
                                                         
                # If the instrument IS in window_tracker
                if inst in self.window_tracker[site].keys():
                    # Check if there has been a data gap
                    wts = self.window_tracker[site][inst]['t0i']
                    wte = wts + self.window_sec
                    # If the next window endtime is before the minimum instrument starttime, advance window
                    if wte < dst_inst.stats.min_starttime:
                        dt_adv = dst_inst.stats.min_starttime - wte
                        nadv = dt_adv//self.advance_sec
                        self.window_tracker[site][inst]['t0i'] += (nadv + 1)*self.advance_sec
    
    def sample_windows(self, x):
        if not isinstance(x, DictStream):
            raise TypeError
        nnew = 0
        # Create split view of input at instrument level
        split_dict = x.split_on_key(key='instrument')
        for site, subdict in self.window_tracker.items():
            for inst, metadata in subdict.items():
                wts = metadata['t0i']
                nrc = metadata['nrc']
                # Skip init_t0
                if f'{site}.{inst}' in split_dict.keys():
                    _dst = split_dict[f'{site}.{inst}']
                    _rdst = _dst.split_on_key(key='component')[nrc]
                    # If the reference component is present
                    if len(_rdst) == 1:
                        # If the reference component valid fraction is at/above the threshold
                        if _rdst[0].fvalid >= self.ref['threshold']:
                            # Create trimmed copies of the MLTraceBuffer data
                            traces = []
                            # Iterate across mltracebuffer objects to sample traces and stamp ID with model name
                            for _mltb in _dst:
                                if isinstance(_mltb, MLTraceBuffer):
                                    # Use trim_copy method of MLTraceBuffer to create a trimmed MLTrace copy
                                    _mlt = _mltb.trim_copy(starttime=wts,
                                                           endtime=wts + self.window_sec,
                                                           **self.options)
                                    # Update model string in MLTraceStats
                                    _mlt.stats.model = self.model_name
                                    # Append to trace list
                                    traces.append(_mlt)
                                else:
                                    raise TypeError(f'WindowWyrm expects to sample from MLTraceBuffer type objects. Not {type(_mltb)}')
                            # Compose ComponentStream header items
                            header = _dst.stats.copy()
                            header.update({'reference_starttime': wts,
                                           'reference_sampling_rate': self.ref['sampling_rate'],
                                           'reference_npts': self.ref['npts']})
                            # initialize ComponentStream
                            cst = ComponentStream(traces=traces, header=header, component_aliases=self.aliases)
                            # append to queue
                            self.queue.append(cst)
                            # update this site-inst's window starttime
                            self.window_tracker[site][inst] += self.advance_sec
                            # update the number of new windows index for this call
                            nnew += 1
                        else:
                            # If there is insufficient reference data, do noting
                            pass
                    elif len(_rdst) == 0:
                        # If the reference component is not present, do nothing
                        pass
                    else:
                        raise ValueError('Multiple reference component traces detected!')
                else:
                    # If site.inst code is not in the input dictstream, pass
                    pass
            # End of INST for loop
        # End of SITE for loop
        return nnew

            
    def update_from_seisbench(self, model):
        """
        Helper method for (re)setting the window-defining attributes for this
        WindowWyrm object from a seisbench.models.WaveformModel object:

            self.model_name = model.name
            self.ref['sampling_rate'] = model.sampling_rate
            self.ref['npts'] = model.in_samples
            self.ref['overlap'] = model._annotate_args['overlap'][1]

        """
        if not isinstance(model, sbm.WaveformModel):
            raise TypeError
        elif model.name != 'WaveformModel':
            if model.sampling_rate is not None:
                self.ref.update({'sampling_rate': model.sampling_rate})
            if model.in_samples is not None:
                self.ref.update({'npts': model.in_samples})
            self.ref.update({'overlap': model._annotate_args['overlap'][1]})
            self.model_name = model.name
        else:
            raise TypeError('seisbench.models.WaveformModel base class does not provide the necessary update information')

    def __repr__(self):
        """
        Provide a user-friendly string representation of this WindowWyrm's parameterization
        and state.
        """
        rstr = f'WindowWyrm for model architecture "{self.model_name}"\n'
        rstr += 'Ref.:'
        for _k, _v in self.ref.items():
            if _k in ['overlap', 'npts']:
                rstr += f' {_k}:{_v} samples |'
            elif _k == "sampling_rate":
                rstr += f' {_k}: {_v} sps |'
            elif _k == 'component':
                rstr += f' {_k}:"{_v}" |'
            elif _k == 'threshold':
                rstr += f' {_k}:{_v:.3f}'
        rstr += '\nAliases '
        for _k, _v in self.aliases.items():
            rstr += f' "{_k}":{[__v for __v in _v]}'
        rstr += f'\nIndex: {len(self.window_tracker)} sites |'
        _ni = 0
        for _v in self.window_tracker.values():
            _ni += len(_v) - 1
        types = {}
        for _x in self.queue:
            if type(_x).__name__ not in types.keys():
                types.update({type(_x).__name__: 1})
            else:
                types[type(_x).__name__] += 1
        rstr += f' {_ni} instruments {_ni}'
        rstr += '\nQueue: '
        for _k, _v in types.items():
            rstr += f'{_v} {_k}(s) | '
        rstr = rstr[:-3]
            
        return rstr
    
    def __str__(self):
        """
        Provide a string representation of this WindowWyrm's initialization
        """
        rstr = 'wyrm.core.process.WindowWyrm('
        rstr += f'component_aliases={self.aliases}, '
        rstr += f'reference_component="{self.ref["component"]}", '
        rstr += f'reference_completeness_threshold={self.ref["threshold"]}, '
        rstr += f'model_name="{self.model_name}", '
        rstr += f'reference_sampling_rate={self.ref["sampling_rate"]}, '
        rstr += f'reference_npts={self.ref["npts"]}, '
        rstr += f'reference_overlap={self.ref["overlap"]}, '
        rstr += f'max_pulse_size={self.max_pulse_size}, '
        rstr += f'debug={self.debug}'
        for _k, _v in self.options.items():
            if isinstance(_v, str):
                rstr += f', {_k}="{_v}"'
            else:
                rstr += f', {_k}={_v}'
        rstr += ')'
        return rstr

###################################################################################
# METHOD WYRM CLASS DEFINITION - FOR EXECUTING CLASS METHODS IN A PULSED MANNER ###
###################################################################################

class MethodWyrm(Wyrm):
    """
    A submodule for applying a class method with specified key-word arguments to objects
    sourced from an input deque and passed to an output deque (self.queue) following processing.

    NOTE: This submodule assumes that applied class methods apply in-place alterations on data

    """
    def __init__(
        self,
        pclass=ComponentStream,
        pmethod="filter",
        pkwargs={'type': 'bandpass',
                 'freqmin': 1,
                 'freqmax': 45},
        max_pulse_size=10000,
        debug=False,
        ):
        """
        Initialize a MethodWyrm object

        :: INPUTS ::
        :param pclass: [type] class defining object (ComponentStream, MLStream, etc.)
        :param pmethod: [str] name of class method to apply 
                            NOTE: sanity checks are applied to ensure that pmethod is in the
                                attributes and methods associated with pclass
        :param pkwargs: [dict] dictionary of key-word arguments (and positional arguments
                                stated as key-word arguments) for pclass.pmethod(**pkwargs)
                            NOTE: only sanity check applied is that pkwargs is type dict.
                                Users should refer to the documentation of their intended
                                pclass.pmethod() to ensure keys and values are compatable.
        :param max_pulse_size: [int] positive valued maximum number of objects to process
                                during a call of MethodWyrm.pulse()
        :param debug: [bool] should this Wyrm be run in debug mode?

        """

        # Initialize/inherit from Wyrm
        super().__init__(max_pulse_size=max_pulse_size, debug=debug)
        # pclass compatability checks
        if not isinstance(pclass,type):
            raise TypeError('pclass must be a class defining object (type "type")')
        else:
            self.pclass = pclass
        # pmethod compatability checks
        if pmethod not in [func for func in dir(self.mclass) if callable(getattr(self.mclass, func))]:
            raise ValueError(f'pmethod "{pmethod}" is not defined in {self.mclass} properties or methods')
        else:
            self.pmethod = pmethod
        # pkwargs compatability checks
        if isinstance(pkwargs, dict):
            self.pkwargs = pkwargs
        else:
            raise TypeError
        # initialize output queue
        self.queue = deque()

    def pulse(self, x):
        """
        Execute a pulse wherein items are popleft'd off input deque `x`,
        checked if they are type `pclass`, have `pmethod(**pkwargs)` applied,
        and are appended to deque `self.queue`. Items popped off `x` that
        are not type pclass are reappended to `x`.

        Early stopping is triggered if `x` reaches 0 elements or the number of
        iterations equals the initial len(x)

        :: INPUT ::
        :param x: [deque] of [pclass (ideally)]

        :: OUTPUT ::
        :return y: [deque] access to the objects in self.queue
        """
        if not isinstance(x, deque):
            raise TypeError
        qlen = len(x)
        for _i in range(self.max_pulse_size):
            # Early stopping if all items have been assessed
            if _i - 1 > qlen:
                break
            # Early stopping if input deque is exhausted
            if len(x) == 0:
                break
            
            _x = x.popleft()
            if not isinstance(_x, self.pclass):
                x.append(_x)
            else:
                getattr(_x, self.pmethod)(**self.pkwargs);
                self.queue.append(_x)
        y = self.queue
        return y
    
###################################################################################
# PREDICTION WYRM CLASS DEFINITION - FOR BATCHED PREDICTION IN A PULSED MANNER ####
###################################################################################
    
class PredictionWyrm(Wyrm):
    """
    Conduct ML model predictions on preprocessed data ingested as a deque of
    ComponentStream objects using one or more pretrained model weights. Following
    guidance on model application acceleration from SeisBench, an option to precompile
    models on the target device is included as a default option.

    This Wyrm's pulse() method accepts a deque of preprocessed ComponentStream objects
    and outputs to another deque (self.queue) of MLTrace objects that contain
    windowed predictions, source-metadata, and fold values that are the sum of the
    input data fold vectors
        i.e., data with all 3 data channels has predictions with fold = 3 for all elements, 
              whereas data with both horizontal channels missing produce predictions with 
              fold = 1 for all elements. Consequently data with gaps may have fold values
              ranging \in [0, 3]

    This functionality allows tracking of information density across the prediction stage
    of a processing pipeline.
    """
    def __init__(
        self,
        model=sbm.EQTransformer(),
        weight_names=['pnw',
                      'instance',
                      'stead'],
        devicetype='cpu',
        compiled=True,
        max_pulse_size=1000,
        debug=False):
        """
        Initialize a PredictionWyrm object

        :: INPUTS ::
        :param model: [seisbench.models.WaveformModel] child class object
        :param weight_names: [list-like] of [str] names of pretrained model
                        weights included in the model.list_pretrained() output
                        NOTE: This object holds distinct, in-memory instances of
                            all model-weight combinations, allowing rapid cycling
                            across weights and storage of pre-compiled models
        :param devicetype: [str] name of a device compliant with a torch.device()
                            object and the particular hardware of the system running
                            this instance of Wyrm 
                                (e.g., on Apple M1/2 'mps' becomes an option)
        :param compiled: [bool] should the model(s) be precompiled on initialization
                            using the torch.compile() method?
                        NOTE: This is suggested in the SeisBench documentation as
                            a way to accelerate model application
        :param max_pulse_size: [int] - maximum BATCH SIZE for windowed data
                            to pass to the model(s) for a single call of self.pulse()
        :debug: [bool] should this wyrm be run in debug mode?

        """
        super().__init__(max_pulse_size=max_pulse_size, debug=debug)
        
        # model compatability checks
        if not isinstance(model, sbm.WaveformModel):
            raise TypeError('model must be a seisbench.models.WaveformModel object')
        elif model.name == 'WaveformModel':
            raise TypeError('model must be a child-class of the seisbench.models.WaveformModel class')
        else:
            self.model = model
        
        # Model weight_names compatability checks
        pretrained_list = model.list_pretrained()
        if isinstance(weight_names, str):
            weight_names = [weight_names]
        elif isinstance(weight_names, (list, tuple)):
            if not all(isinstance(_n, str) for _n in weight_names):
                raise TypeError('not all listed weight_names are type str')
        else:
            for _n in weight_names:
                if _n not in pretrained_list:
                    raise ValueError(f'weight_name {_n} is not a valid pretrained model weight_name for {model}')
        self.weight_names = weight_names

        # device compatability checks
        if not isinstance(devicetype, str):
            raise TypeError('devicetype must be type str')
        else:
            try:
                device = torch.device(devicetype)
            except RuntimeError:
                raise RuntimeError(f'devicetype {devicetype} is an invalid device string for PyTorch')
            try:
                self.model.to(device)
            except RuntimeError:
                raise RuntimeError(f'device type {devicetype} is unavailable on this installation')
            self.device = device
        
        # Preload/precompile model-weight combinations
        if isinstance(compiled, bool):    
            self.compiled = compiled
        else:
            raise TypeError(f'"compiled" type {type(compiled)} not supported. Must be type bool')

        self.cmods = {}
        for wname in self.weight_names:
            if self.debug:
                print(f'Loading {self.model.name} - {wname}')
            cmod = self.model.from_pretrained(wname)
            if compiled:
                if self.debug:
                    print(f'...pre compiling model on device type "{self.device.type}"')
                cmod = torch.compile(cmod.to(self.device))

            self.cmods.update({wname: cmod})
        # Initialize output deque
        self.queue = deque()

    def pulse(self, x):
        """
        Execute a pulse on input deque of ComponentStream objects `x`, predicting
        values for each model-weight-window combination and outputting individual
        predicted value traces as MLTrace objects in the self.queue attribute

        :: INPUT ::
        :param x: [deque] of [wyrm.core.dictstream.ComponentStream] objects
                    objects must be 
        

        TODO: Eventually, have the predictions overwrite the windowed data
              values of the ingested ComponentStream objects so predictions
              largely work as a in-place change
        """
        if not isinstance(x, deque):
            raise TypeError('input "x" must be type deque')
        
        qlen = len(x)
        # Initialize batch collectors for this pulse
        batch_data = []
        batch_fold = []
        batch_meta = []

        for _i in range(self.max_pulse_size):
            if len(x) == 0:
                break
            if _i == qlen:
                break
            else:
                _x = x.popleft()
                if not(isinstance(_x, ComponentStream)):
                    x.append(_x)
                # Check that ComponentStream is ready to split out, copy, and be eliminated
                if _x.ready_to_burn(model):
                    # Part out copied data, metadata, and fold objects
                    _data = _x.to_torch(model).copy()
                    _fold = _x.collapse_fold().copy() 
                    _meta = _x.stats.copy()
                    # Delete source ComponentStream object to clean up memory
                    del _x
                    # Append copied (meta)data to collectors
                    batch_data.append(torch.Tensor(_data))
                    batch_fold.append(_fold)
                    batch_meta.append(_meta)
                # TODO: If not ready to burn, kick error
                else:
                    raise ValueError('ComponentStream is not sufficiently preprocessed - suspect an error earlier in the tube')
        # Concatenate batch_data tensor list into a single tensor
        batch_data = torch.concat(batch_data)
        # Iterate across preloaded (and precompiled) models
        for wname, model in self.cmods.items():
            # Run batch prediction for a given model weight
            batch_pred = self.run_prediction(model, batch_data, batch_meta)
            # Reassociate window metadata to predicted values and send MLTraces to queue
            self.batch2queue(model, wname, batch_pred, batch_fold, batch_meta)
        # Provide access to queue as pulse output
        y = self.queue
        return y

    def run_prediction(self, model, batch_data, reshape_output=True):
        """
        Run a prediction on an input batch of windowed data using a specified model on
        self.device. Provides checks that batch_data is on self.device and an option to
        enforce a uniform shape of batch_preds and batch_data.

        :: INPUT ::
        :param model: [seisbench.models.WaveformModel] initialized model object with
                        pretrained weights loaded (and potentialy precompiled) with
                        which this prediction will be conducted
        :param batch_data: [numpy.ndarray] or [torch.Tensor] data array with scaling
                        appropriate to the input layer of `model` 
        :reshape_output: [bool] if batch_preds has a different shape from batch_data
                        should batch_preds be reshaped to match?
        :: OUTPUT ::
        :return batch_preds: [torch.Tensor] prediction outputs 
        """
        # Ensure input data is a torch.tensor
        if not isinstance(batch_data, (torch.Tensor, np.ndarray)):
            raise TypeError('batch_data must be type torch.Tensor or numpy.ndarray')
        elif isinstance(batch_data, np.ndarray):
            batch_data = torch.Tensor(batch_data)

        # RUN PREDICTION, ensuring data is on self.device
        if batch_data.device.type != self.device.type:
            batch_preds = model(batch_data.to(self.device))
        else:
            batch_preds = model(batch_data)
        
        # Check if output predictions are presented as some list-like of torch.Tensors
        if isinstance(batch_preds, (tuple, list)):
            # If so, convert into a torch.Tensor
            if all(isinstance(_p, torch.Tensor) for _p in batch_preds):
                batch_preds = torch.concat(batch_preds)
            else:
                raise TypeError('not all elements of preds is type torch.Tensor')
        # If reshaping to batch_data.shape is desired, check if it is required.
        if reshape_output and batch_preds.shape != batch_data.shape:
            batch_preds.reshape(batch_data.shape)

        return batch_preds

    def batch2queue(self, weight_name, batch_preds, batch_fold, batch_meta):
        """
        Reassociated batched predictions, batched metadata, and model metadata to generate MLTrace objects
        that are appended to the output deque (self.queue). The following MLTrace ID elements are updated
            component = 1st letter of the model label (e.g., "Detection" from EQTranformer -> "D")
            model = model name
            weight = pretrained weight name
        

        :: INPUTS ::
        :param weight_name: [str] name of the pretrained model weight used
        :param batch_preds: [torch.Tensor] predicted values with expected axis assignments:
                                axis 0: window # - corresponding to the axis 0 values in batch_fold and batch_meta
                                axis 1: label - label assignments from the model architecture used
                                axis 2: values
        :param batch_fold: [list] of [numpy.ndarray] vectors of summed input data fold for each input window
        :param batch_meta: [list] of [wyrm.core.dictstream.ComponentStreamStats] objects corresponding to
                                input data for each prediction window
        
        :: OUTPUT ::
        None

        :: ATTR UPDATE ::
        :attr queue: [deque] MLTrace objects generated as shown below are appended to `queue`
                    for window _i and predicted value label _j
                       mlt = MLTrace(data=batch_pred[_i, _j, :], fold = batch_fold[_i, :], header=batch_meta[_i])

        """
        # Detach prediction array and convert to numpy
        if batch_preds.device.type != 'cpu':
            batch_preds = batch_preds.detach().cpu().numpy()
        else:
            batch_preds = batch_preds.detach().numpy()
        # Iterate across metadata dictionaries
        for _i, _meta in batch_meta:
            # Iterate across prediction labels
            for _j, label in enumerate(self.model.labels):
                # Compose output trace from prediction values, input data fold, and header data
                _mlt = MLTrace(data = batch_preds[_i, _j, :], fold=batch_fold[_i, :], header=_meta)
                # Update component labeling
                _mlt.set_component(new_label=label)
                # Update weight name in mltrace header
                _mlt.stats.weight = weight_name
                # Add mltrace to dsbuffer (subsequent buffering to happen in the next step)
                self.queue.append(_mlt)

