"""
:module: wyrm.util.stacking
:auth: Nathan T. Stevens
:email: ntsteven (at) uw.edu
:org: Pacific Northwest Seismic Network
:license: AGPL-3.0

:purpose:
    This module contains subroutines built on numpy that facilitate overlapping
    array stacking and buffering, largely used by the RtPredBuff class, and
    coherence/semblance methods based on code from the ELEP project (Yuan et al., 2023)

:references:
Yuan, C, Ni, Y, Lin, Y, Denolle, M, 2023, Better Together: Ensemble Learning for Earthquake
    Detection and Phase Picking. IEEE Transactions on Geoscience and Remote Sensing, 61,
    doi: 10.1109/TGRS.2023.3320148

"""

import numpy as np
import scipy.ndimage as nd

def shift_trim(array, npts_right, axis=None, fill_value=np.nan, dtype=None, **kwargs):
    """
    Execute a shift of values along a specified axis (default 0-axis),
    omitting (trimming) samples that fall out of the reference frame of the
    array and padding unoccupied sample positions with a specified `fill_value`

    Operation generates a copy of input `array` data, with modifications

    :: INPUTS ::
    :param array: [numpy.ndarray] target array to shift
    :param npts_right: [int] number of samples to shift contents, with a
                positive value indicating a rightward (increasing index)
                shift and a negative value indicating a leftward (decreasing
                index) shift
    :param axis: [int] axis over which to enact the leftshift
    :param fill_value: [scalar] fill_value to insert into empty index positions
                generated by shifting and trimming

    Benchmarking shows that the index-reassignment approach done here
    is more computationally efficient compared to roll_trim_rows below by 
    about a factor of 3

    """
    if not isinstance(array, np.ndarray):
        raise TypeError('input "array" must be type numpy.ndarray')
    
    if not isinstance(npts_right, (int, float)):
        raise TypeError('npts_right must be int-like')
    elif isinstance(npts_right, float):
        npts_right = int(npts_right)
    
    if axis is None:
        pass
    elif axis + 1 > len(array.shape):
        raise IndexError(f'Axis {axis} is outside the dimensionality of array ({array.shape})')

    
    # End processing and return 
    if npts_right == 0:
        return array.copy()
    else:
        if dtype is None:
            tmp_array = np.full(shape=array.shape, fill_value=fill_value, dtype=array.dtype, **kwargs)
        else:
            tmp_array = np.full(shape=array.shape, fill_value=fill_value, **kwargs)

        # If ellipsis use case
        if axis is None:
            # rightshift
            if npts_right > 0:
                tmp_array[npts_right:, ...] = array.copy()[:-npts_right, ...]
            # leftshift
            elif npts_right < 0:
                tmp_array[:npts_right, ...] = array.copy()[-npts_right:, ...]
            
        elif axis + 1 == array.ndim or axis == -1:
            # rightshift
            if npts_right > 0:
                tmp_array[..., npts_right:] = array.copy()[..., :-npts_right]
            # leftshift
            elif npts_right < 0:
                tmp_array[..., :npts_right] = array.copy()[..., -npts_right:]
        # hack-ey use of 'eval' to do dynamic indexing
        elif axis + 1 < array.ndim:
            # Start eval strings for indexing
            tmp_index = '['
            array_index = '['
            for _i in range(array.ndim):
                # If this is not the target axis, insert :
                if _i != axis:
                    tmp_index += ':'
                    array_index += ':'
                # If this is the target axis
                else:
                    # append rightshift slice
                    if npts_right > 0:
                        tmp_index += 'npts_right:'
                        array_index += ':-npts_right'
                    # append lefshift slice
                    elif npts_right < 0:
                        tmp_index += ':-npts_right'
                        array_index == 'npts_right:'
                # If this isn't the final axis, append a comma
                if _i + 1 < len(array.shape):
                    tmp_index += ', '
                    array_index += ', '
                # Otherwise, close out eval str
                else:
                    tmp_index += ']'
                    array_index += ']'
            eval(f'tmp_array{tmp_index} = array.copy(){array_index}')
    
    return tmp_array

def sum2(arr):
    """"""
    return sum(arr)

def semblance(pstack, order=2, semb_npts=101, method='np', eta=1e-9, weighted=True):
    """
    Calculate coherence via semblance analysis

    Based on ELEP's ensemble_coherence method
    Yuan et al. (2023) and references therein

    Semblance:
    semb(t) = MAX[m](P(m,t))*C[m,t](P(m,t))**order

    Coherence:
    C(P(t)) = sum[ti, tj]{sum[m]{P(m,t)**2}}/
                M*sum[ti,tj]{sum[m]{P(m,t)**2}}

    With M = the number of entries in "m"

    :: INPUTS ::
    :param pstack: [numpy.ndarray] containing stacked, synchronous windowed
                    prediction outputs from "m" model-weight combinations
                    for a given prediction label "l" time-series with sample
                    points "t".
                    This version requires the following axis assignment
                        pstack [m, l, t]
                            or
                        pstack [m, t]
                        when run in method = 'nd'
                    or generally
                        pstack [m, ..., t]
                        when run in method = 'np'
 
                    NOTE
                    If mixing model types (i.e., EQTransformer & PhaseNet)
                    care is required to make sure l-axis inputs are compatable
                    i.e., use prediction labels 1 (P-detection) and 2 (S-detection)
                        but likely omit label 0 (Detection for EqT, Noies for PhaseNet)

    :param order: [int] exponent to apply to the semblance term
    :param semb_npts: [int] number of samples in the window [ti, tj]
            NOTE: computational cost scales roughly linearly with semb_npts
    :param method: [str] method flag for the algorithm to produce rolling windows
                of stack along the t_axis.
            Supported:
                "nd" - use SciPy's ndimage.generic_filter() method (after Yuan et al., 2023)
                        Slightly less computationally efficient, but provides estimates
                        at the edges of arrays.
                "np" - use NumPy's lib.stride_tricks.sliding_window_view() method
                        Slightly more computationally efficient, but blinds the
                        first and last semb_npts/2 points in each row vector of semb_array
                        (blind = np.nan)
    :param eta: [float] very small floating point number added to the denominator of
                C(P(t)) to prevent division by 0. Default is 1e-9. 
    :param weighted: [bool] should the MAX weighting term be applied?
                        True - yes
                        False - weighting is uniformly 1
                        
    :: OUTPUT ::
    :return semb_array: [numpy.ndarray] containing semblance time-series with dimensionality
                semb_array [l, t] for input pstack [m, l, t]
                    or
                semb_array [t] for input pstack [m, t]
    """
    # TODO - compatability checks
    if eta < 0:
        eta = np.abs(eta)

    if weighted:
        # Calculate max weighting for each P(l,t)
        wt = np.max(pstack,axis=0)
    else:
        wt = np.ones(shape=pstack.shape[1:])

    if method == 'np':
        # Preallocate output array
        semb_array = np.full(shape=pstack.shape[1:],
                            fill_value=np.nan,
                            dtype=pstack.dtype)
        # Get first write location
        first_t = semb_npts//2
        # Generate views
        views = np.lib.stride_tricks.sliding_window_view(pstack, semb_npts, axis=-1)
        # Calculate numerator
        num = np.sum(np.sum(views, axis=0)**2, axis=-1)
        # Calculate denominator
        den = pstack.shape[0]*np.sum(views**2, axis=(0,-1))
        semb_array[..., first_t: first_t + views.shape[-2]] = (num/(den+eta))**order
        semb_array *= wt

    if method == 'nd':
        # Calculate internal sum/square combinations
        sq_sums = np.sum(pstack, axis=0)**2
        sum_sqs = np.sum(pstack**2, axis=0)
        # Iterate across labels
        if pstack.ndim == 3:
            for _l in range(pstack.shape[1]):
                # Apply 
                num = nd.generic_filter(sq_sums[_l, :], sum, semb_npts, mode='constant')
                den = pstack.shape[0]*nd.generic_filter(sum_sqs[_l, :], sum, semb_npts, mode='constant')
                semb_array[_l, :] = wt[_l, :]*(num/(den+eta))**order
        # Handle case where label axis has been squeezed
        elif pstack.ndim == 2:
            num = nd.generic_filter(sq_sums, sum, semb_npts, mode='constant')
            den = pstack.shape[0]*nd.generic_filter(sum_sqs, sum, semb_npts, mode='constant')
            semb_array = wt*(num/(den+eta))**order


    return semb_array