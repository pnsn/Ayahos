import fnmatch, inspect, time, warnings, os, glob, obspy
import numpy as np
import pandas as pd
from decorator import decorator
from obspy.core.utcdatetime import UTCDateTime
from obspy.core.stream import Stream, read
from obspy.core.trace import Trace
from obspy.core.util.attribdict import AttribDict
from obspy.core import compatibility
from wyrm.core.mltrace import MLTrace, read_mltrace
from wyrm.util.pyew import wave2mltrace
from wyrm.util.semblance import ensemble_semblance #, weighted_ensemble_semblance


def read_mltraces(data_files, obspy_read_kwargs={}, add_options={}):
    """
    Wrapper around the wyrm.data.mltrace.MLTrace.read_mltrace() method
    to reconstitute multiple MLTrace objects from the _DATA, _FOLD, _PROC
    files generated by the MLTrace.write() method and populate a WyrmStream
    object. 

    :: INPUTS ::
    :param data_files: [str] file name of a {COMMON_NAME}_DATA.{EXTENSION}
                    file that contains MLTrace data and header information
                       [list] list of valid data_file name strings
                    also see wyrm.data.mltrace.read_mltrace()
    :obspy_read_kwargs: [dict] dictionar of keyword arguments to pass to
                    obspy.core.stream.read()
    :add_options: [dict] dictionary of keyword arguments to pass to
                    wyrm.data.WyrmStream.WyrmStream.__add__

    :: OUTPUT ::
    :return dst: [wyrm.data.WyrmStream.WyrmStream] assembled WyrmStream object
    
    {common_name}_DATA.{extension} 
    """
    if isinstance(data_files, str):
        data_files = [data_files]
    elif not isinstance(data_files, list):
        raise TypeError
    else:
        if not all(isinstance(_e, str) for _e in data_files):
            raise TypeError
    
    dst = WyrmStream()
    for df in data_files:
        mlt = read_mltrace(df, **obspy_read_kwargs)
        dst.__add__(mlt, **add_options)
    return dst

def read_from_numpy(file_list, dst_options={}, read_options={}):
    if isinstance(file_list, str):
        file_list = [file_list]
    mltr_list = []
    for _f in file_list:
        _fn, _ext = os.path.splitext(_f)
        mltr_list.append(MLTrace.read_from_numpy_hdr(_fn, **read_options))
    dst = WyrmStream(traces=mltr_list, **dst_options)
    return dst
        


# def read_from_tiered_directory(root_path, common_string, key_attr='id', **options):
    
#     glob_DATA = os.path.join(root_path, 'DATA', f'{common_string}_DATA.*')
#     gd = glob.glob(glob_DATA)
#     if len(gd) == 0:
#         raise ValueError(f'glob.glob({glob_DATA}) returned 0 entries')
#     else:
#         dst = WyrmStream()
#         for _f in gd:
#             try:
#                 tr = read(_f)[0]
#             except TypeError:
#                 raise TypeError(f'Unknown format for file {_f}')
#             # Get file name
#             path, file_ext = os.path.split(_f)
#             file, ext = os.path.splitext(file_ext)
#             # Get id from start of file name
#             parts = file.split('_')
#             id = parts[0]
#             common_name = '_'.join(parts[:-1])
#             # Break into components
#             n,s,l,c,m,w = id.split('.')
#             # initialize MLTrace with tr as information
#             mlt = MLTrace(data=tr)
#             # Update model
#             mlt.stats.model=m
#             # Update weight
#             mlt.stats.weight=w
#             # Try to find fold and processing information
#             fold_file = os.path.join(root_path,'FOLD',f'{common_name}_FOLD.{ext}')
#             proc_file = os.path.join(root_path,'PROC',f'{common_name}_PROC.txt')
#             # If fold file is found
#             if os.path.exists(fold_file):
#                 ftr = read(fold_file)[0]
#                 mlt.fold = ftr.data
#             # If processing file is found
#             if os.path.isfile(proc_file):
#                 with open(proc_file, 'r') as _p:
#                     lines = _p.readlines()
#                 for _l in lines:
#                     # Strip newline character
#                     _l = _l[:-1]
#                     # Split comma separated into list
#                     _l = _l.split(',')
#                     # Append to processing
#                     mlt.stats.processing.append(_l)
#                 _p.close()
#             dst.__add__(mlt, key_attr=key_attr, **options)
#     return dst



###################################################################################
# Dictionary Stream Stats Class Definition ########################################
###################################################################################

class WyrmStreamStats(AttribDict):
    """
    A class to contain metadata for a wyrm.core.WyrmStream.WyrmStream object
    of the based on the ObsPy AttribDict (Attribute Dictionary) class. 

    This operates very similarly to obspy.core.trace.Trace objects' Stats object
    (a sibling class)
    """
    defaults = {
        'common_id': '*',
        'min_starttime': None,
        'max_starttime': None,
        'min_endtime': None,
        'max_endtime': None,
        'processing': []
    }

    _types = {'common_id': str,
              'min_starttime': (type(None), UTCDateTime),
              'max_starttime': (type(None), UTCDateTime),
              'min_endtime': (type(None), UTCDateTime),
              'max_endtime': (type(None), UTCDateTime)}

    def __init__(self, header={}):
        """
        Initialize a WyrmStreamStats object

        :: INPUT ::
        :param header: [dict] (optional)
                    Dictionary defining attributes (keys) and 
                    values (values) to assign to the WyrmStreamStats
                    object
        """
        super(WyrmStreamStats, self).__init__()
        self.update(header)
    
    def _pretty_str(self, priorized_keys=[], hidden_keys=[], min_label_length=16):
        """
        Return better readable string representation of AttribDict object.

        NOTE: Slight adaptation of the obspy.core.util.attribdict.AttribDict
                _pretty_str method, adding a hidden_keys argument

        :type priorized_keys: list[str], optional
        :param priorized_keys: Keywords of current AttribDict which will be
            shown before all other keywords. Those keywords must exists
            otherwise an exception will be raised. Defaults to empty list.
        :param hidden_keys: [list] of [str]
                        Keywords of current AttribDict that will be hidden
                        NOTE: does not supercede items in prioritized_keys
        :type min_label_length: int, optional
        :param min_label_length: Minimum label length for keywords. Defaults
            to ``16``.
        :return: String representation of current AttribDict object.
        """
        keys = list(self.keys())
        # determine longest key name for alignment of all items
        try:
            i = max(max([len(k) for k in keys]), min_label_length)
        except ValueError:
            # no keys
            return ""
        pattern = "%%%ds: %%s" % (i)
        # check if keys exist
        other_keys = [k for k in keys if k not in priorized_keys and k not in hidden_keys]
        # priorized keys first + all other keys
        keys = priorized_keys + sorted(other_keys)
        head = [pattern % (k, self.__dict__[k]) for k in keys]
        return "\n".join(head)


    def __str__(self):
        prioritized_keys = ['common_id',
                            'min_starttime',
                            'max_starttime',
                            'min_endtime',
                            'max_endtime',
                            'processing']
        return self._pretty_str(prioritized_keys)

    def _repr_pretty_(self, p, cycle):
        p.text(str(self))

    # def __repr__(self):
    #     """
    #     Provide a user-friendly string representation of the contents of this WyrmStreamStats object
    #     """
    #     rstr = '----Stats----'
    #     for _k, _v in self.items():
    #         if _v is not None:
    #             if self.min_starttime != self.max_starttime or self.min_endtime != self.max_endtime:
    #                 if 'min_' in _k:
    #                     if _k == 'min_starttime':
    #                         rstr += f'\n{"min time range":>18}: {self.min_starttime} - {self.min_endtime}'
    #                 elif 'max_' in _k:
    #                     if _k == 'max_starttime':
    #                         rstr += f'\n{"max time range":>18}: {self.max_starttime} - {self.max_endtime}'
    #             elif 'time' in _k:
    #                 if _k == 'min_starttime':
    #                     rstr += f'\n{"uniform range":>18}: {self.min_starttime} - {self.min_endtime}'
    #             else:
    #                 rstr += f'\n{_k:>18}: {_v}'
    #     return rstr

    def update_time_range(self, trace):
        """
        Update the minimum and maximum starttime and endtime attributes of this
        WyrmStreamStats object using timing information from an obspy Trace-like
        object.

        :: INPUT ::
        :param trace: [obspy.core.trace.Trace] or child classes from which to 
                    query starttime and endtime information
        """
        if self.min_starttime is None or self.min_starttime > trace.stats.starttime:
            self.min_starttime = trace.stats.starttime
        if self.max_starttime is None or self.max_starttime < trace.stats.starttime:
            self.max_starttime = trace.stats.starttime
        if self.min_endtime is None or self.min_endtime > trace.stats.endtime:
            self.min_endtime = trace.stats.endtime
        if self.max_endtime is None or self.max_endtime < trace.stats.endtime:
            self.max_endtime = trace.stats.endtime

@decorator
def _add_processing_info(func, *args, **kwargs):
    """
    This is a decorator that attaches information about a processing call as a string
    to the WyrmStream.stats.processing lists

    Attribution: Directly adapted from the obspy.core.trace function of the same name.
    """
    callargs = inspect.getcallargs(func, *args, **kwargs)
    callargs.pop("self")
    kwargs_ = callargs.pop("kwargs", {})
    info = [time.time(), "Wyrm 0.0.0","{function}".format(function=func.__name__), "(%s)"]
    arguments = []
    arguments += \
        ["%s=%s" % (k, repr(v)) if not isinstance(v, str) else
         "%s='%s'" % (k, v) for k, v in callargs.items()]
    arguments += \
        ["%s=%s" % (k, repr(v)) if not isinstance(v, str) else
         "%s='%s'" % (k, v) for k, v in kwargs_.items()]
    arguments.sort()
    info[-1] = info[-1] % "::".join(arguments)
    self = args[0]
    result = func(*args, **kwargs)
    # Attach after executing the function to avoid having it attached
    # while the operation failed.
    self._internal_add_processing_info(info)
    return result

###################################################################################
# Dictionary Stream Class Definition ##############################################
###################################################################################

class WyrmStream(Stream):
    """
    An adaptation of the obspy.core.stream.Stream class that provides a dictionary
    housing for multiple wyrm.core.trace.MLTrace objects and a header object
    that tracks timing and processing metadata for its contents. Updated methods
    are provided to allow use of obspy.core.stream.Stream class methods, along
    with new methods oriented towards processing tasks in the Wyrm workflow. 

    NOTE: Not all inherited methods are supported, which will be addressed
        on an as-needed basis.
    """
    _max_processing_info = 100
    def __init__(self, traces=None, header={}, key_attr='id', **options):
        """
        Initialize a WyrmStream object

        :: INPUTS ::
        :param traces: [obspy.core.trace.Trace] or [list-like] thereof
                        that are added to the self.traces attribute via
                        the __add__ method.
        :param header: [dict] dict stream header information
                        see wyrm.core.WyrmStream.WyrmStreamStats
        :param options: [kwargs] collector for kwargs to pass to WyrmStream.__add__
                        when adding traces to this WyrmStream during initialization
                        NOTE: unlike other methods (i.e., MLTraceBuffer) these
                                kwargs are not saved as defaults.
        """
        # initialize as empty stream
        super().__init__()
        # Create stats attribute with WyrmStreamStats
        self.stats = WyrmStreamStats(header=header)
        # Redefine self.traces as dict
        self.traces = {}
        # TODO: Need some safety catches if a plain-vanilla obspy.Trace is introduced
        self._attr_keys = ['id', 'site','inst','instrument','mod','component']
        if key_attr in self._attr_keys:
            self.default_key_attr = key_attr
        else:
            raise ValueError
        
        if traces is not None:
            self.__add__(traces, key_attr=self.default_key_attr, **options)
            self.stats.common_id = self.get_common_id()


    def _internal_add_processing_info(self, info):
        """
        Add the given informational string to the `processing` field in the
        WyrmStream's :class:`wyrm.core.WyrmStream.WyrmStreamStats` object.
        """
        proc = self.stats.setdefault('processing', [])
        if len(proc) == self._max_processing_info-1:
            msg = ('List of processing information in Trace.stats.processing '
                   'reached maximal length of {} entries.')
            warnings.warn(msg.format(self._max_processing_info))
        if len(proc) < self._max_processing_info:
            proc.append(info)

    #####################################################################
    # MAGIC METHOD UPDATES ##############################################
    #####################################################################
            
    def __iter__(self):
        """
        Return a robust iterator for WyrmStream.traces to iterate
        across keyed values (i.e., list(self.traces.values()))
        """
        return list(self.traces.values()).__iter__()
    
    def __getitem__(self, index):
        """
        Fusion between the __getitem__ method for lists and dictionaries
        This accepts integer and slice indexing to access items in
        WyrmStream.traces, as well as str-type key values. 

        __getitem__ calls that retrieve a single trace return a trace-type object
        whereas calls that retrieve multiple traces return a WyrmStream object

        Because the WyrmStream class defaults to using trace.id values for
        keys (which are str-type), this remove the ambiguity in the expected
        type for self.traces' keys.

        :: INPUTS ::
        :param index: [int] - returns the ith trace in list(self.traces.values())
                      [slice] - returns a WyrmStream with the specified slice from 
                            list(self.traces.values())
                      [str] - returns the trace corresponding to self.traces[index]
                      [list] of [str] - return a WyrmStream containing the traces as 
                            specified by a list of trace keys
        
        :: OUTPUT ::
        :return out: see INPUTS
        """
        # Handle single item fetch
        if isinstance(index, int):
            trace = self.traces[list(self.traces.keys())[index]]
            out = trace
        # Handle slice fetch
        elif isinstance(index, slice):
            keyslice = list(self.traces.keys()).__getitem__(index)
            traces = [self.traces[_k] for _k in keyslice]
            out = self.__class__(traces=traces)
        # Preserve dict.__getitem__ behavior for string arguments
        elif isinstance(index, str):
            if index in self.traces.keys():
                out = self.traces[index]
            else:
                raise KeyError(f'index {index} is not a key in this WyrmStream\'s traces attribute')
        elif isinstance(index, list):
            if all(isinstance(_e, str) and _e in self.traces.keys() for _e in index):
                traces = [self.traces[_k] for _k in index]
                out = self.__class__(traces=traces)
            else:
                raise KeyError('not all keys in index are str-type and keys in this WyrmStream\'s traces attribute')
        else:
            raise TypeError('index must be type int, str, list, or slice')
        return out
    
    def __setitem__(self, index, trace):
        if isinstance(index, int):
            key = list(self.traces.keys())[index]
        elif isinstance(index, str):
            key = index
        else:
            raise TypeError(f'index type {type(index)} not supported. Only int and str')
        self.traces.update({key, trace})

    def __delitem__(self, index):
        if isinstance(index, str):
            key = index
        elif isinstance(index, int):
            key = list(self.traces.keys())[index]
        else:
            raise TypeError(f'index type {type(index)} not supported. Only int and str')   
        self.traces.__delitem__(key)


    def __getslice__(self, i, j, k=1):
        """
        Updated __getslice__ that leverages the WyrmStream.__getitem__ update
        from comparable magic methods for obspy.core.stream.Stream.
        """
        return self.__class__(traces=self[max(0,i):max(0,j):k])

    def __add__(self, traces, **options):
        """
        Alias for the WyrmStream.extend() method to allow
        use of the += operator

        """
        self.extend(traces, **options)            

    def extend(self, other, key_attr=None, **options):
        """
        Wrapper method for the _add_trace() method that
        allows input of single or sets of Trace-type objects
        to append to this WyrmStream with a specified key_attribute
        """
        if key_attr is None:
            key_attr = self.default_key_attr
        elif key_attr not in self._attr_keys:
            raise ValueError

        if isinstance(other, Trace):
            self._add_trace(other, key_attr=key_attr, **options)
        elif isinstance(other, Stream):
            self._add_stream(other, key_attr=key_attr, **options)
        elif isinstance(other, (list, tuple)):
            if all(isinstance(_tr, Trace) for _tr in other):
                self._add_stream(other, key_attr=key_attr, **options)
            else:
                raise TypeError('other elements are not all Trace-like types')
        else:
            raise TypeError(f'other type "{type(other)}" not supported.')

    def _add_trace(self, other, key_attr=None, **options):
        """
        Add a trace-like object `other` to this WyrmStream using elements from
        the trace's id as the dictionary key in the WyrmStream.traces dictionary

        :: INPUTS ::
        :param other: [obspy.core.trace.Trace] or child-class
                        Trace to append
        :param key_attr: [str] optional name of the attribute to use as a key.
                        Supercedes the default value set in WyrmStream.__init__()
                        Supported Values:
                            'id' - full N.S.L.C(.M.W) code
                            'site' - Net + Station
                            'inst' - Location + Band & Instrument codes from Channel
                            'instrument'- 'site' + 'inst'
                            'mod' - Model + Weight codes
                            'component' - component code from Channel
        :param **options: [kwargs] key-word argument gatherer to pass to the 
                        MLTrace.__add__() or MLTraceBuffer.__add__() method
        """
        if key_attr is None:
            key_attr = self.default_key_attr
        elif key_attr not in self._attr_keys:
            raise ValueError
        
        # If potentially appending a wave
        if isinstance(other, dict):
            try:
                other = wave2mltrace(other)
            except SyntaxError:
                pass
        # If appending a trace-type object
        elif isinstance(other, Trace):
            # If it isn't an MLTrace, __init__ one from data & header
            if not isinstance(other, MLTrace):
                other = MLTrace(data=other.data, header=other.stats)
            else:
                pass
        # Otherwise
        else:
            raise TypeError(f'other {type(other)} not supported.')
        
        if isinstance(other, MLTrace):
            # Get id of MLTrace "other"
            key_opts = other.key_opts
            # If id is not in traces.keys() - use dict.update
            key = key_opts[key_attr]
            # If new key
            if key not in self.traces.keys():
                self.traces.update({key: other})
            # If key is in traces.keys() - use __add__
            else:
                self.traces[key].__add__(other, **options)
            self.stats.update_time_range(other)
            self.stats.common_id = self.get_common_id()

    def _add_stream(self, stream, **options):
        """
        Supporting method to iterate across a stream-like object
        and apply the _add_trace() WyrmStream class method

        :: INPUTS ::
        :param stream: [obspy.core.stream.Stream] or similar
                        an iterable object that returns individual
                        obspy Trace-like objects as iterants
        :param **options: [kwargs] optional key-word argument gatherer
                        to pass kwargs to the WyrmStream._add_trace method
        """
        for _tr in stream:
            self._add_trace(_tr, **options)

    def __str__(self):
        rstr = 'wyrm.core.data.WyrmStream()'
        return rstr

    def __repr__(self, extended=False):
        rstr = f'--Stats--\n{self.stats.__str__()}\n-------'
        if len(self.traces) > 0:
            id_length = max(len(_tr.id) for _tr in self.traces.values())
        else:
            id_length=0
        if len(self.traces) > 0:
            rstr += f'\n{len(self.traces)} {type(self[0]).__name__}(s) in {type(self).__name__}\n'
        else:
            rstr += f'\nNothing in {type(self).__name__}\n'
        if len(self.traces) <= 20 or extended is True:
            for _l, _tr in self.traces.items():
                rstr += f'{_l:} : {_tr.__str__(id_length)}\n'
        else:
            _l0, _tr0 = list(self.traces.items())[0]
            _lf, _trf = list(self.traces.items())[-1]
            rstr += f'{_l0:} : {_tr0.__repr__(id_length=id_length)}\n'
            rstr += f'...\n({len(self.traces) - 2} other traces)\n...\n'
            rstr += f'{_lf:} : {_trf.__repr__(id_length=id_length)}\n'
            rstr += f'[Use "print({type(self).__name__}.__repr__(extended=True))" to print all labels and MLTraces]'
        return rstr
    
    #####################################################################
    # WRITE METHOD ######################################################
    #####################################################################

    # def write_to_mseed(
    #         self,
    #         savepath='.',
    #         save_fold=True,
    #         fmt_str='{ID}_{t0:.3f}_{t1:.3f}_{sampling_rate:.3f}sps',
    #         save_processing=True,
    #         save_empty=False,
    #         **kwargs):
    #     split_outs = {}
    #     for _mlt in self.traces.items():
    #         if not save_empty and _mlt.stats.npts == 0:
    #             continue
    #         else:
    #             out = _mlt.write_to_tiered_directory(
    #                 savepath=savepath,
    #                 save_fold=save_fold,
    #                 save_processing=save_processing,
    #                 fmt_str = fmt_str,
    #                 **kwargs)
    #             split_outs.update({_mlt.id: out})
    #     return split_outs


    # def write(
    #         self,
    #         save_path='.',
    #         fmt='sac',
    #         save_fold=True,
    #         save_processing=True,
    #         filename_format='{ID}_{starttime}_{sampling_rate:.3f}sps',
    #         **obspy_write_options):
    #     """
    #     Wrapper around the wyrm.data.mltrace.MLTrace.write() method
    #     that saves data as 
        
    #     """
    #     for _mlt in self.traces.values():
    #         _mlt.write(save_path=save_path,
    #                    fmt=fmt,
    #                    save_fold=save_fold,
    #                    save_processing=save_processing,
    #                    filename_format=filename_format,
    #                    **obspy_write_options)
    def write(self, base_path='.', path_structure='mltraces', name_structure='{wfid}_{iso_start}', **options):
        """
        Write a WyrmStream object to disk as a series of MSEED files using the MLTrace.write() method/file formatting
        in a prescribed directory structure

        :: INPUTS ::
        :param base_path: [str] path to the directory that will contain the save file structure. If it does
                    not exist, a directory (structure) will be created
        :param path_structure: [None] - no intermediate path structure
                                [str] - format string based on the metadata of individual MLTrace objects contained
                                        in this WyrmStream. In addition to standard kwargs in the MLTrace.stats
                                        that can be used as elements of this format string, additional options are
                                        provided for datetime information:
                                            epoch_start - starttimes converted into a timestamp
                                            epoch_end - endtimes converted into timestamps
                                            iso_start - starttimes converted into isoformat strings
                                            iso_ends - endtimes converted into isoformat strings
                                            wfid - waveform ID (Net.Sta.Loc.Chan.Mod.Wgt)
                                            site - Net.Sta code string
                                            inst - Loc.Chan (minus the component character) code string
                                            mod - Mod.Wgt code string
                                            instrument - site.inst (as defined above) code string
        :param name_structure: [str] - format string with the opions as described for path_structure
        :param **options: [kwargs] optional key word argument collector for 

        :ATTRIBUTION: Based on path sturcturing and syntax from the ObsPlus WaveBank class
        
        """
        # # Ensure OS-appropriate path formatting
        # base_parts = os.path.split(base_path)
        # base_path = os.path.join(base_parts)

        # Get elements of the save directory structure as an OS-agnostic list of directory names
        if path_structure is None:
            path_parts = [base_path]
        else:
            path_parts = [base_path] + path_structure.split('/')
        # Iterate across traces in this WyrmStream
        for tr in self.traces.values():
            # Ge the formatting dictionary 
            fmt_dict = {'wfid': tr.id,
                        'epoch_start': tr.stats.starttime.timestamp,
                        'iso_start': tr.stats.starttime.isoformat(),
                        'epoch_end': tr.stats.endtime.timestamp,
                        'iso_end': tr.stats.endtime.isoformat()}
            fmt_dict.update(tr.stats)
            if isinstance(tr, MLTrace):
                fmt_dict.update({'component': tr.comp,
                                 'site': tr.site,
                                 'inst': tr.inst,
                                 'mod': tr.mod,
                                 'instrument': tr.instrument})

            save_path = os.path.join(*path_parts).format(**fmt_dict)
            save_name = f'{name_structure.format(**fmt_dict)}.mseed'
            file_name = os.path.join(save_path, save_name)
            if not os.path.exists(save_path):
                os.makedirs(save_path)
            tr.write(file_name=file_name, **options)

    def read(mltrace_mseed_files):
        if isinstance(mltrace_mseed_files, str):
            mltrace_mseed_files = [mltrace_mseed_files]
        dst = WyrmStream()
        for file in mltrace_mseed_files:
            if not os.path.isfile(file):
                raise FileExistsError(f'file {file} does not exist')
            else:
                mltr = MLTrace.read(file)
            dst.extend(mltr)
        return dst


    
    #####################################################################
    # SEARCH METHODS ####################################################
    #####################################################################
    
    def fnselect(self, fnstr, key_attr=None, ascopy=False):
        """
        Find WyrmStream.traces.keys() strings that match the
        input `fnstr` string using the fnmatch.filter() method
        and compose a view (or copy) of the subset WyrmStream

        :: INPUTS ::
        :param fnstr: [str] Unix wildcard compliant string to 
                        use for searching for matching keys
        :param key_attr: [str] - key attribute for indexing this view/copy
                        of the source WyrmStream (see WyrmStream.__init__)
                         [None] - defaults to the .default_key_attr attribute
                         value of the source WyrmStream object
        :param ascopy: [bool] should the returned WyrmStream
                        be a view (i.e., accessing the same memory blocks)
                        or a copy of the traces contained within?

        :: OUTPUT ::
        :return out: [wyrm.core.WyrmStream.WyrmStream] containing
                        subset traces that match the specified `fnstr`
        """
        matches = fnmatch.filter(self.traces.keys(), fnstr)
        out = self.__class__(header=self.stats.copy(), key_attr = self.default_key_attr)
        for _m in matches:
            if ascopy:
                _tr = self.traces[_m].copy()
            else:
                _tr = self.traces[_m]
            out.extend(_tr, key_attr=key_attr)
        out.stats.common_id = out.get_common_id()
        return out
    
    def isin(self, iterable, key_attr=None, ascopy=False):
        """
        Return a subset view (or copy) of the contents of this
        WyrmStream with keys that conform to an iterable set
        of strings.

        Generally based on the behavior of the pandas.series.Series.isin() method

        TODO: make sure the WyrmStream.extend() method is not
              creating

        :: INPUTS ::
        :param iterable: [list-like] of [str] - strings to match
                            NOTE: can accept wild-card strings 
                                (also see WyrmStream.fnselect)
        :param key_attr: [str] - key attribute for indexing this view/copy
                        of the source WyrmStream (see WyrmStream.__init__)
                         [None] - defaults to the .default_key_attr attribute
                         value of the source WyrmStream object
        :param ascopy: [bool] return as an independent copy of the subset?
                        default - False
                            NOTE: this creates a view that can
                            alter the source WyrmStream's contents
        :: OUTPUT ::
        :return out: [wyrm.data.WyrmStream.WyrmStream] subset view/copy
        """
        out = self.__class__(header=self.stats.copy(), key_attr = self.default_key_attr)
        matches = []
        for _e in iterable:
            matches += fnmatch.filter(self.traces.keys(), _e)
        for _m in matches:
            if ascopy:
                _tr = self.traces[_m].copy()
            else:
                _tr = self.traces[_m]
            out.extend(_tr, key_attr=key_attr)
        out.stats.common_id = out.get_common_id()
        return out

    def exclude(self, iterable, key_attr=None, ascopy=False):
        out = self.__class__(header=self.stats.copy(), key_attr = self.default_key_attr)
        matches = []
        for _e in iterable:
            matches += fnmatch.filter(self.traces.keys(), _e)
        for _k in self.traces.keys():
            if _k not in matches:
                if ascopy:
                    _tr = self.traces[_k].copy()
                else:
                    _tr = self.traces[_k]
                out.extend(_tr, key_attr=key_attr)
        out.stats.common_id = out.get_common_id()
        return out


    def get_unique_id_elements(self):
        """
        Compose a dictionary containing lists of
        unique id elements: Network, Station, Location,
        Channel, Model, Weight in this WyrmStream

        :: OUTPUT ::
        :return out: [dict] output dictionary keyed
                by the above elements and valued
                as lists of strings
        """
        N, S, L, C, M, W = [], [], [], [], [], []
        for _tr in self:
            hdr = _tr.stats
            if hdr.network not in N:
                N.append(hdr.network)
            if hdr.station not in S:
                S.append(hdr.station)
            if hdr.location not in L:
                L.append(hdr.location)
            if hdr.channel not in C:
                C.append(hdr.channel)
            if hdr.model not in M:
                M.append(hdr.model)
            if hdr.weight not in W:
                W.append(hdr.weight)
        out = dict(zip(['network','station','location','channel','model','weight'],
                       [N, S, L, C, M, W]))
        return out
    
    def get_common_id_elements(self):
        """
        Return a dictionary of strings that are 
        UNIX wild-card representations of a common
        id for all traces in this WyrmStream. I.e.,
            ? = single character wildcard
            * = unbounded character count widlcard

        :: OUTPUT ::
        :return out: [dict] dictionary of elements keyed
                    with the ID element name
        """
        ele = self.get_unique_id_elements()
        out = {}
        for _k, _v in ele.items():
            if len(_v) == 0:
                out.update({_k:'*'})
            elif len(_v) == 1:
                out.update({_k: _v[0]})
            else:
                minlen = 999
                maxlen = 0
                for _ve in _v:
                    if len(_ve) < minlen:
                        minlen = len(_ve)
                    if len(_ve) > maxlen:
                        maxlen = len(_ve)
                _cs = []
                for _i in range(minlen):
                    _cc = _v[0][_i]
                    for _ve in _v:
                        if _ve[_i] == _cc:
                            pass
                        else:
                            _cc = '?'
                            break
                    _cs.append(_cc)
                if all(_c == '?' for _c in _cs):
                    _cs = '*'
                else:
                    if minlen != maxlen:
                        _cs.append('*')
                    _cs = ''.join(_cs)
                out.update({_k: _cs})
        return out

    def get_common_id(self):
        """
        Get the UNIX wildcard formatted common common_id string
        for all traces in this WyrmStream

        :: OUTPUT ::
        :return out: [str] output stream
        """
        ele = self.get_common_id_elements()
        out = '.'.join(ele.values())
        return out

    def update_stats_timing(self):
        for tr in self:
            self.stats.update_time_range(tr)
        return None                
    
    def split_on_key(self, key='instrument', **options):
        """
        Split this WyrmStream into a dictionary of WyrmStream
        objects based on a given element or elements of the
        constituient traces' ids.

        :: INPUTS ::
        :param key: [str] name of the attribute to split on
                    Supported:
                        'id', 'site','inst','instrument','mod','component',
                        'network','station','location','channel','model','weight'
        :param **options: [kwargs] key word argument gatherer to pass
                        kwargs to WyrmStream.__add__()
        :: OUTPUT ::
        :return out: [dict] of [WyrmStream] objects
        """
        if key not in MLTrace().key_opts.keys():
            raise ValueError(f'key {key} not supported.')
        out = {}
        for _tr in self:
            key_opts = _tr.key_opts
            _k = key_opts[key]
            if _k not in out.keys():
                out.update({_k: self.__class__(traces=_tr)})
            else:
                out[_k].__add__(_tr, **options)
        return out
    
    def to_component_streams(self, component_aliases={'Z': 'Z3', 'N': 'N1', 'E': 'E2'}, ascopy=False, **options):
        """
        Split this WyrmStream by instrument codes (Net.Sta.Loc.BandInst)
        """
        from wyrm.streaming.windowstream import ComponentStream
        # Split by instrument_id
        if ascopy:
            out = self.copy().split_on_key(key='instrument', **options)
        else:
            out = self.split_on_key(key='instrument', **options)
        # Iterate and update
        for _k, _v in out.items():
            out.update({_k: ComponentStream(traces=_v, component_aliases=component_aliases)})
        return out
    

    # def split(self, keys=('site', 'instrument'), flat=True, **options):
    #     if isinstance(keys, str):
    #         keys = (keys)
    #     if not all(_k in MLTrace().key_opts.keys() for _k in keys):
    #         raise ValueError
        
    #     out = {}
    #     for _tr in self:    
    #         _kl = []
    #         for _k in keys:
    #             _kl.append(_k)
    #         if flat:
    #             _out_key = '_'.join(_kl)
    #         else:
    #             for _k in _kl[::-1]:
    #                 _x
    #####################################################################
    # UPDATED METHODS FROM OBSPY STREAM #######################################
    #####################################################################
    # @_add_processing_info
    def trim(self,
             starttime=None,
             endtime=None,
             pad=True,
             keep_empty_traces=True,
             nearest_sample=True,
             fill_value=None):
        """
        Slight adaptation of obspy.core.stream.Stream.trim() to facilitate the dict-type self.traces
        attribute syntax.

        see obspy.core.stream.Stream.trim() for full explanation of the arguments and behaviors
        
        :: INPUTS ::
        :param starttime: [obspy.core.utcdatetime.UTCDateTime] or [None]
                        starttime for trim on all traces in WyrmStream
        :param endtime: [obspy.core.utcdatetime.UTCDateTime] or [None]
                        endtime for trim on all traces in WyrmStream
        :param pad: [bool]
                        should trim times outside bounds of traces
                        produce masked (and 0-valued fold) samples?
                        NOTE: In this implementation pad=True as default
        :param keep_empty_traces: [bool]
                        should empty traces be kept?
        :param nearest_sample: [bool]
                        should trim be set to the closest sample(s) to 
                        starttime/endtime?
        :param fill_value: [int], [float], or [None]
                        fill_value for gaps - None results in masked
                        data and 0-valued fold samples in gaps
    
        """
        if not self:
            return self
        # select start/end time fitting to a sample point of the first trace
        if nearest_sample:
            tr = self[0]
            try:
                if starttime is not None:
                    delta = compatibility.round_away(
                        (starttime - tr.stats.starttime) *
                        tr.stats.sampling_rate)
                    starttime = tr.stats.starttime + delta * tr.stats.delta
                if endtime is not None:
                    delta = compatibility.round_away(
                        (endtime - tr.stats.endtime) * tr.stats.sampling_rate)
                    # delta is negative!
                    endtime = tr.stats.endtime + delta * tr.stats.delta
            except TypeError:
                msg = ('starttime and endtime must be UTCDateTime objects '
                       'or None for this call to Stream.trim()')
                raise TypeError(msg)
        for trace in self:
            trace.trim(starttime, endtime, pad=pad,
                       nearest_sample=nearest_sample, fill_value=fill_value)
            self.stats.update_time_range(trace)
        if not keep_empty_traces:
            # remove empty traces after trimming
            self.traces = {_k: _v for _k, _v in self.traces.items() if _v.stats.npts}
            self.stats.update_time_range(trace)
        self.stats.common_id = self.get_common_id()
        return self
    
    def normalize_traces(self, norm_type:str ='peak'):
        for tr in self:
            tr.normalize(norm_type=norm_type)
    

    #######################
    # VISUALIZATION TOOLS #  
    #######################
    def _to_vis_stream(self, fold_threshold=0, normalize_src_traces=True, attach_mod_to_loc=True):
        st = obspy.Stream()
        for mltr in self:
            tr = mltr.copy()
            if normalize_src_traces:
                if mltr.stats.weight == mltr.stats.defaults['weight']:
                    tr = tr.normalize(norm_type='max')
            st += tr.to_trace(fold_threshold=fold_threshold,
                              attach_mod_to_loc=attach_mod_to_loc)
        return st

    def plot(self, fold_threshold=0, attach_mod_to_loc=True, normalize_src_traces=False, **kwargs):
        st = self._to_vis_stream(fold_threshold=fold_threshold,
                                 normalize_src_traces=normalize_src_traces,
                                 attach_mod_to_loc=attach_mod_to_loc)
        outs = st.plot(**kwargs)
        return outs
    
    def snuffle(self, fold_threshold=0, attach_mod_to_loc=True, normalize_src_traces=True,**kwargs):
        if 'obspy_compat' not in dir():
            from pyrocko import obspy_compat
            obspy_compat.plant()
        st = self._to_vis_stream(fold_threshold=fold_threshold,
                                 normalize_src_traces=normalize_src_traces,
                                 attach_mod_to_loc=attach_mod_to_loc)
        outs = st.snuffle(**kwargs)
        return outs
                    
    

    ######################
    # SEMBLANCE STACKING #
    ######################

    def semblance(
            self,
            window_len=0.5,
            order=2,
            coefficient='max',
            fold_weighted=False,
            fill_value=0,
            trim_type='inner',
            dtype=np.float32):
        """
        OOP API for the ELEP ensemble_semblance method from Yuan et al. (2023)

  


        :: INPUTS ::
        :param window_len: [float] window length for semblance calculation
                            maps to paras['semblance_win'] in ELEP semblance
        :param order: [float] enhanced coherence exponent.
                            maps to paras['semblance_order']
                            Default 2 from Yuan et al., (2023)
        :param coefficient: [str] coefficient type for enhanced coherence
                            Supported:
                      (Default) 'max' - maximum value at time sample ti
                                'mean' - mean value of samples at time sample ti
                                'mean_std' - mean/std of samples at time sample ti
                            Maps to paras['weight_flag']
        :param fold_weighted: [bool] should a fold-weighted semblance be calculated?
                            NOTE: Currently not implemented
                                DEFAULT FALSE
        :param fill_value: fill_value to pass to MLTrace.trimmed_copy() and
                            MLTrace.sync_to_window() methods
        :param trim_type: [str] how trimming should be conducted using WyrmStream
                            header information
                            Supported:
                                'inner': max_starttime -> min_endtime
                                'outer': min_starttime -> max_endtime
        :param dtype: [type] numpy data type to use internally
                        Default is numpy.float32
        
        :: OUTPUT ::
        :return mlt_semb: [wyrm.data.mltrace.MLTrace] (if len(self) > 1)
                MLTrace object with
                    data = semblance trace
                    fold = sum of contributors' fold
                    id = self.stats.common_id (via source attribute assignments)
                    starttime from trimming
                if len(self) == 1
                    Returns a view of the single trace in this WyrmStream
                if len(self) == 0
                    Returns an empty MLTrace object
        """
        if len(self) == 1:
            return self[0]
        elif len(self) == 0:
            return MLTrace()
        else:
            # Create dictionary holder for `paras` param
            paras = {'semblance_win': window_len,
                    'semblance_order': order,
                    'weight_flag': coefficient,
                    }
            # Sanity check that sampling rates are the same
            if not all(_tr.stats.sampling_rate == self[0].stats.sampling_rate for _tr in self):
                raise ValueError('sampling_rate values mismatch in this WyrmStream, cannot run semblance')
            else:
                paras.update({'dt': self[0].stats.delta})
                if self[0].stats.delta < window_len:
                    paras.update({'window_flag': True})
                else:
                    paras.update({'window_flag': False})
            if trim_type == 'inner':
                ts = self.stats.max_starttime
                te= self.stats.min_endtime
            elif trim_type == 'outer':
                ts = self.stats.min_starttime
                te = self.stats.max_endtime
            else:
                raise ValueError(f'trim_type {trim_type} not supported.')
            
            data = []
            fold = []
            min_npts = 9e99
            # Get trimmed copies of data in traces
            header = {}
            for tr in self:
                # Capture all combinations of NSLCMW code elements for output
                for _k in ['network','station','location','channel','model','weight']:
                    if _k not in header:
                        header.update({_k: []})
                    if tr.stats[_k] not in header[_k]:
                        header[_k].append(tr.stats[_k])
                # Create a trimmed copy
                tr_trim = tr.trimmed_copy(starttime=ts,
                                        endtime=te,
                                        pad=True,
                                        fill_value=fill_value)
                # Attempt to handle misalignment
                if not tr_trim.is_utcdatetime_in_sampling(ts):
                    tr_trim.sync_to_window(starttime=ts,
                                        fill_value=fill_value)
                # Capture minimum data length
                if tr_trim.stats.npts < min_npts:
                    min_npts = tr_trim.stats.npts
                # Grab data and fold vectors 
                data.append(tr_trim.data)
                fold.append(tr_trim.fold)
            # Compose data array input(s), trimming off extra trailing samples
            signals = np.array([d_[:min_npts].astype(dtype) for d_ in data])
            weights = np.array([f_[:min_npts].astype(dtype) for f_ in fold])
            # Merge lists of NSLCMW code elements into strings
            for _k, _v in header.items():
                header.update({_k: '|'.join(_v)})
            # Assess if fold should be used as a weighting
            if fold_weighted:
                raise NotImplementedError
                # semblance = weighted_ensemble_semblance(signals, weights, paras)

            else:
                semblance = ensemble_semblance(signals, paras)

            # Get starttime  and sampling_rate from processing
            header.update({'starttime': ts, 'sampling_rate': 1/paras['dt']})
            # Create a new attribute documenting the contributing ids for clarity
            header.update({'contributors': list(self.traces.keys())})
            # Create a new MLTrace to hold the semblance output
            mlt_semb = MLTrace(data=semblance, fold=weights.sum(axis=0), header=header)
            return mlt_semb

    def prediction_trigger_report(self, thresh, exclude_list=None, **kwargs):
        df_out = pd.DataFrame()
        if 'include_processing_info' in kwargs.keys():
            include_proc = kwargs['include_processing_info']
        else:
            include_proc = False
        if include_proc:
            df_proc = pd.DataFrame()
        if exclude_list is not None:
            if isinstance(exclude_list, list) and all(isinstance(_e, str) for _e in exclude_list):
                view = self.exclude(exclude_list)
            else:
                raise TypeError('exclude_list must be a list of strings or NoneType')
        else:
            view = self
        for tr in view.traces.values():
            out = tr.prediction_trigger_report(thresh, **kwargs)
            # Parse output depening on output type
            if not include_proc and out is not None:
                idf_out = out
            elif include_proc and out is not None:
                idf_out = out[0]
                idf_proc = out[1]
            # Concatenate outputs
            if out is not None:
                df_out = pd.concat([df_out, idf_out], axis=0, ignore_index=True)
                if include_proc:
                    df_proc = pd.concat([df_proc, idf_proc], axis=0, ignore_index=True)
            else:
                continue
        if len(df_out) > 0:
            if include_proc:
                return df_out, df_proc
            else:
                return df_out
        else:
            return None



    ###############
    # I/O METHODS - TODO - GO THROUGH SAC TO APPEND MOD TO CHANNEL #
    ###############

#     def write(self, dirname, **options):
#         # Create a stream to use ObsPy's I/O routines for saving to a directory name
        
#         stream = Stream()
#         for _tr in self:
#             if _tr.mod != '.':
#                 mod = f'{_tr.stats.model}.{_tr.stats.weight}'
#             else:
#                 mod = ''
#             data = _tr.data
#             tr_fold = _tr.get_fold_trace()
#             # Tack model information into Network metadata
#             tr_fold.stats.network += f'_{mod}'


#             hdr = _tr.stats
#             header = Stats()
#             for _k in header.defaults.keys():
#                 header.update({_k: self.stats[_k]})
#             tr_data = Trace(data=data, header=header)
#             tr_data.stats.network += f'_{mod}'
            
#             stream += tr_fold
#             stream += tr_data

#         out = stream.write(filename, format='MSEED', **options)
#         return out

# def read_from_sac(filenames, **options):
#     st = Stream()

#     st = read(filename, fmt='MSEED', **options)
#     dst = WyrmStream()
#     holder = {}
#     for tr in st:
#         if '_' in tr.stats.network:
#             net, mod, wgt = tr.stats.network.split('_')
#         else:
#             net, mod, wgt, = tr.stats.network, '', ''
#         hdr = tr.stats
#         hdr.update({'network': net, 'model': mod, 'weight': wgt})
#         instrument_id = f'{hdr.network}.{hdr.station}.{hdr.location}.{hdr.channel[:-1]}?.{hdr.model}.{hdr.weight}'
#         if instrument_id in holder.keys():
#             if component != 'f':

        
#         component = hdr.component
#         if component == 'f':


#         if instrument_id in holder.keys():
#             holder[instrument_id].update({component: bundle})
#         else:
#             holder.update({instrument_id: {component: bundle}})

        
#         bundle = {'data': tr.data, ''}
#         mltr = MLTrace(data=tr.data, header=hdr)



    





            
